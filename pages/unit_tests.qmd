---
title: "Unit tests"
---

```{r}
#| include: false
library(reticulate)
use_condaenv("hdruk_tests", required = TRUE)
```

{{< include /assets/language-selector.html >}}

## What is a unit test?

A **unit** test checks one small, isolated unit of code - usually a single function or method. Your aim is to check that, for specific inputs, the function behaves exactly as promised.

## Example: `import_patient_data()`

Let's use the `import_patient_data()` function from our case study. Its main behaviours are that it:

1. Reads a CSV into a pandas DataFrame.
2. Requires the columns to match a specific list exactly (names and order).
3. Raises a `ValueError` if columns are incorrect.
4. Returns a DataFrame with raw patient-level data.

```{python}
import pandas as pd
from pathlib import Path
import pytest
```

```{python}
#| file: code/import_patient_data.py
```

## How to write unit tests

### 1. Start from the docstring

Always write docstrings for your functions and classes (see [our docstring tutorial](https://pythonhealthdatascience.github.io/des_rap_book/pages/guide/style_docs/docstrings.html) if you need guidance).

Your docstring makes **promises** about how the function should behave. For `import_patient_data()`, the docstring promises it will:

* Accept `str` or `Path` as the `path` parameter
* Return a pandas DataFrame
* Raise `ValueError` if columns are incorrect

Each of these becomes something you can check with a test.

### 2. Define what "success" looks like

Pick the simplest input that should work.

In our case, we can create a small CSV with correct columns in the right order and one or two data rows. We can then write tests that confirm:

* The result is a pandas DataFrame.
* The columns match exactly: `list(df.columns) == expected_list`

::: {.callout-note title="Why test columns if the function already checks them?"}

Because we are testing the **promised** behaviour of the function, not just trusting its current implementation.

If someone edits the code later and accidentally removes that validation, your test will catch it!

:::

```{python}
def test_import_success(tmp_path):
    """Small CSV with correct columns should work."""

    expected_cols = [
        "PATIENT_ID", "ARRIVAL_DATE", "ARRIVAL_TIME",
        "SERVICE_DATE", "SERVICE_TIME",
    ]

    # Create temporary CSV file
    df = pd.DataFrame(
        [["p1", "2024-01-01", "08:00", "2024-01-01", "09:00"]],
        columns=expected_cols,
    )
    csv_path = tmp_path / "patients.csv"
    df_in.to_csv(csv_path, index=False)

    # Run function and check it looks correct
    result = import_patient_data(csv_path)
    assert isinstance(result, pd.DataFrame)
    assert list(result.columns) == expected_cols
    pd.testing.assert_frame_equal(result, df_in)
```

### 3. List ways things can go wrong

Now think: how can inputs break the promises?

For `import_patient_data()`, a `ValueError` should be raised when we have:

* Missing columns
* Extra columns
* Correct columns but wrong order

For each case, we can create a small DataFrame which triggers the problem and assert that a `ValueError` is raised.

```{python}
@pytest.mark.parametrize(
    "columns",
    [
        # Example 1: Missing columns
        [
            "PATIENT_ID", "ARRIVAL_DATE", "ARRIVAL_TIME", "SERVICE_DATE"
        ],
        # Example 2: Extra columns
        [
            "PATIENT_ID", "ARRIVAL_DATE", "ARRIVAL_TIME",
            "SERVICE_DATE", "SERVICE_TIME", "EXTRA",
        ],
        # Example 3: Right columns, wrong order
        [
            "ARRIVAL_DATE", "PATIENT_ID", "ARRIVAL_TIME",
            "SERVICE_DATE", "SERVICE_TIME",
        ],
    ],
)
def test_import_errors(tmp_path, columns):
    """Incorrect columns should trigger ValueError."""

    # Create temporary CSV file
    df_in = pd.DataFrame([range(len(columns))], columns=columns)
    csv_path = tmp_path / "patients.csv"
    df_in.to_csv(csv_path, index=False)

    # Check it raises ValueError
    with pytest.raises(ValueError):
        import_patient_data(csv_path)
```

### 4. Consider edge cases

Edge cases are inputs that are unusual but still realistic.

For example, what if the CSV has the correct headers but no data? Should that succeed and return an empty DataFrame, or should it fail?

In this case, you might decide that an empty CSV with correct headers is fine and does not raise an error. You may still choose to write a test though, as that makes this decision explicit so other coders know what "correct" means at the edges.

```{python}
def test_import_empty_csv(tmp_path):
    """Empty CSV with correct columns should succeed."""
    
    expected_cols = [
        "PATIENT_ID", "ARRIVAL_DATE", "ARRIVAL_TIME",
        "SERVICE_DATE", "SERVICE_TIME",
    ]
    
    # Create empty CSV with correct header
    df_in = pd.DataFrame(columns=expected_cols)
    csv_path = tmp_path / "patients.csv"
    df_in.to_csv(csv_path, index=False)
    
    # Should succeed and return empty DataFrame
    result = import_patient_data(csv_path)
    assert len(result) == 0
    assert list(result.columns) == expected_cols
```

### 5. Test all equivalent input forms

If the function promises to accept multiple equivalent input types, verify they really are equivalent.

With `import_patient_data()`, we expect a `str` or `Path` object to both succeed and return the same DataFrame.

```{python}
def test_import_path_types(tmp_path):
    """str and Path inputs should behave identically."""
    # Create temporary CSV file
    expected_cols = [
        "PATIENT_ID",
        "ARRIVAL_DATE", "ARRIVAL_TIME",
        "SERVICE_DATE", "SERVICE_TIME",
    ]
    df_in = pd.DataFrame(
        [["p1", "2024-01-01", "08:00", "2024-01-01", "09:00"]],
        columns=expected_cols,
    )
    csv_path = tmp_path / "patients.csv"
    df_in.to_csv(csv_path, index=False)

    # Run function with str or Path inputs
    df_str = import_patient_data(str(csv_path))
    df_path = import_patient_data(csv_path)

    # Check that results are the same
    pd.testing.assert_frame_equal(df_str, df_path)
```

## When to stop writing tests

You cannot test everything. You've written enough tests when:

* Every promise in the docstring is tested.
* Every important code branch (like error handling) is tested.

Write additional tests based on real needs (e.g., bug reports, tricky edge cases in your context), and not by trying to anticipate every theoretical failure.

::: {.box-grey}

**In real research projects, you won't unit test every single function or every possible case.** The aim is not perfection, but reasonable confidence in the most important behaviours of your code.

:::
