[
  {
    "objectID": "pages/parametrising_tests.html",
    "href": "pages/parametrising_tests.html",
    "title": "Parameterising tests",
    "section": "",
    "text": "Choose your language:¬†¬†\n    Python\n    R\nThere are many tools you can make use of when testing - one example is parametrising tests.\nWhen you need to test the same logic with different inputs and expected outputs, you can parameterise your tests instead of writing repetitive test functions. This minimises code duplication and makes it easy to add new test cases.",
    "crumbs": [
      "Introduction to writing and running tests",
      "Parameterising tests"
    ]
  },
  {
    "objectID": "pages/parametrising_tests.html#example-testing-summary_stats",
    "href": "pages/parametrising_tests.html#example-testing-summary_stats",
    "title": "Parameterising tests",
    "section": "Example: Testing summary_stats()",
    "text": "Example: Testing summary_stats()\n\nLet‚Äôs say we want to verify that our summary_stats() function works correctly for different datasets. Instead of writing separate test functions for each case, we can use pytest‚Äôs @pytest.mark.parametrize decorator:\n\nimport pandas as pd\nimport pytest\n\n\n@pytest.mark.parametrize(\n    \"data, expected_mean, expected_std, expected_ci_lower, expected_ci_upper\",\n    [\n        # Five value sample with known summary statistics\n        ([1.0, 2.0, 3.0, 4.0, 5.0], 3.0, 1.58, 1.04, 4.96),\n        # No variation: CI collapse to mean\n        ([5, 5, 5], 5, 0, 5, 5),\n    ],\n)\ndef test_summary_stats(\n    data, expected_mean, expected_std, expected_ci_lower, expected_ci_upper\n):\n    \"\"\"Running summary_stats returns expected values.\"\"\"\n    mean, std, ci_lower, ci_upper = summary_stats(pd.Series(data))\n    assert mean == pytest.approx(expected_mean, rel=5e-3)\n    assert std == pytest.approx(expected_std, rel=5e-3)\n    assert ci_lower == pytest.approx(expected_ci_lower, rel=5e-3)\n    assert ci_upper == pytest.approx(expected_ci_upper, rel=5e-3)\n\n\nHow it works\nThe @pytest.mark.parametrize decorator takes two arguments:\n\nParameter names (as a string). These variable names will be passed to your test function. For example:\n\n\"data, expected_mean, expected_std, expected_ci_lower, expected_ci_upper\"\n\nTest cases (as a list of tuples). Each tuple contains values for one test case. For example:\n\n[\n    # Five value sample with known summary statistics\n    ([1.0, 2.0, 3.0, 4.0, 5.0], 3.0, 1.58, 1.04, 4.96),\n    # No variation: CI collapse to mean\n    ([5, 5, 5], 5, 0, 5, 5),\n]\nIf any test case fails, pytest will clearly indicate which parameters were used, making debugging straightforward.\n\n\n\nTODO.",
    "crumbs": [
      "Introduction to writing and running tests",
      "Parameterising tests"
    ]
  },
  {
    "objectID": "pages/parametrising_tests.html#how-it-works",
    "href": "pages/parametrising_tests.html#how-it-works",
    "title": "Parameterising tests",
    "section": "How it works",
    "text": "How it works\nThe @pytest.mark.parametrize decorator takes two arguments:\n\nParameter names (as a string). These variable names will be passed to your test function. For example:\n\n\"data, expected_mean, expected_std, expected_ci_lower, expected_ci_upper\"\n\nTest cases (as a list of tuples). Each tuple contains values for one test case. For example:\n\n[\n    # Five value sample with known summary statistics\n    ([1.0, 2.0, 3.0, 4.0, 5.0], 3.0, 1.58, 1.04, 4.96),\n    # No variation: CI collapse to mean\n    ([5, 5, 5], 5, 0, 5, 5),\n]\nIf any test case fails, pytest will clearly indicate which parameters were used, making debugging straightforward.",
    "crumbs": [
      "Introduction to writing and running tests",
      "Parameterising tests"
    ]
  },
  {
    "objectID": "pages/unit_tests.html",
    "href": "pages/unit_tests.html",
    "title": "Unit tests",
    "section": "",
    "text": "Choose your language:¬†¬†\n    Python\n    R",
    "crumbs": [
      "Types of test",
      "Unit tests"
    ]
  },
  {
    "objectID": "pages/case_study.html",
    "href": "pages/case_study.html",
    "title": "Case study",
    "section": "",
    "text": "Choose your language:¬†¬†\n    Python\n    R\nOur tutorial uses a simple example of importing a small patient dataset and carrying out basic descriptive analysis.\nIn the example we will:",
    "crumbs": [
      "Case study"
    ]
  },
  {
    "objectID": "pages/case_study.html#packages",
    "href": "pages/case_study.html#packages",
    "title": "Case study",
    "section": "Packages",
    "text": "Packages\n\n\nimport json\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport scipy.stats as st\n\npd.set_option(\"display.max_columns\", 8)",
    "crumbs": [
      "Case study"
    ]
  },
  {
    "objectID": "pages/case_study.html#import-patient-data",
    "href": "pages/case_study.html#import-patient-data",
    "title": "Case study",
    "section": "Import patient data",
    "text": "Import patient data\nOur dataset is a small synthetic set of patient-level event times that could come from a healthcare setting (e.g., emergency department, outpatient clinic, doctor‚Äôs appointments). Each row records when a patient arrived and when service began.\n\nOur function import_patient_data() reads the data from a CSV file and checks it contains the expected columns, returning a pandas DataFrame.\n\ndef import_patient_data(path):\n    \"\"\"\n    Import raw patient data and check that required columns are present.\n\n    Parameters\n    ----------\n    path : str or pathlib.Path\n        Path to the CSV file containing the patient data.\n\n    Returns\n    -------\n    pandas.DataFrame\n        Dataframe containing the raw patient-level data.\n\n    Raises\n    ------\n    ValueError\n        If the CSV file does not contain exactly the expected columns\n        in the expected order.\n    \"\"\"\n    df = pd.read_csv(Path(path))\n\n    # Expected columns in the raw data (names and order must match)\n    expected = [\n        \"PATIENT_ID\",\n        \"ARRIVAL_DATE\", \"ARRIVAL_TIME\",\n        \"SERVICE_DATE\", \"SERVICE_TIME\"\n    ]\n    if list(df.columns) != expected:\n        raise ValueError(\n            f\"Unexpected columns: {list(df.columns)} (expected {expected})\"\n        )\n\n    return df\n\n\n\n\n\nWe can run this function on our example dataset patient_data.csv.\nYou can download a copy of this data here:\n Download the example patient-level data \n\n\nraw_data = import_patient_data(\"data/patient_data.csv\")\nraw_data\n\n   PATIENT_ID ARRIVAL_DATE  ARRIVAL_TIME SERVICE_DATE  SERVICE_TIME\n0           1   2025-01-01             1   2025-01-01             7\n1           2   2025-01-01             2   2025-01-01             4\n2           3   2025-01-01             3   2025-01-01            10\n3           4   2025-01-01             7   2025-01-01            14\n4           5   2025-01-01            10   2025-01-01            12\n5           6   2025-01-01            10   2025-01-01            11",
    "crumbs": [
      "Case study"
    ]
  },
  {
    "objectID": "pages/case_study.html#calculate-waiting-times",
    "href": "pages/case_study.html#calculate-waiting-times",
    "title": "Case study",
    "section": "Calculate waiting times",
    "text": "Calculate waiting times\n\nNext, we convert the date and time fields into datetime columns and calculate each patient‚Äôs waiting time in minutes.\n\ndef calculate_wait_times(df):\n    \"\"\"\n    Add arrival/service datetimes and waiting time in minutes.\n\n    Parameters\n    ----------\n    df : pandas.DataFrame\n        Patient-level data containing `ARRIVAL_DATE`, `ARRIVAL_TIME`,\n        `SERVICE_DATE`, and `SERVICE_TIME` columns.\n\n    Returns\n    -------\n    pandas.DataFrame\n        Copy of the input DataFrame with additional columns:\n        `arrival_datetime`, `service_datetime`, and `wait_minutes`.\n    \"\"\"\n    df = df.copy()\n\n    # Combine date and time columns into datetime columns\n    for prefix in (\"ARRIVAL\", \"SERVICE\"):\n        df[f\"{prefix.lower()}_datetime\"] = pd.to_datetime(\n            df[f\"{prefix}_DATE\"].astype(str) +\n            \" \" +\n            df[f\"{prefix}_TIME\"].astype(str).str.zfill(4),\n            format=\"%Y-%m-%d %H%M\",\n        )\n\n    # Waiting time in minutes\n    df[\"wait_minutes\"] = (\n        df[\"service_datetime\"] - df[\"arrival_datetime\"]\n    ) / pd.Timedelta(minutes=1)\n\n    return df\n\n\n\n\n\nWe then apply this function to the raw data.\n\n\nprocessed_data = calculate_wait_times(raw_data)\nprocessed_data\n\n   PATIENT_ID ARRIVAL_DATE  ARRIVAL_TIME SERVICE_DATE  SERVICE_TIME  \\\n0           1   2025-01-01             1   2025-01-01             7   \n1           2   2025-01-01             2   2025-01-01             4   \n2           3   2025-01-01             3   2025-01-01            10   \n3           4   2025-01-01             7   2025-01-01            14   \n4           5   2025-01-01            10   2025-01-01            12   \n5           6   2025-01-01            10   2025-01-01            11   \n\n     arrival_datetime    service_datetime  wait_minutes  \n0 2025-01-01 00:01:00 2025-01-01 00:07:00           6.0  \n1 2025-01-01 00:02:00 2025-01-01 00:04:00           2.0  \n2 2025-01-01 00:03:00 2025-01-01 00:10:00           7.0  \n3 2025-01-01 00:07:00 2025-01-01 00:14:00           7.0  \n4 2025-01-01 00:10:00 2025-01-01 00:12:00           2.0  \n5 2025-01-01 00:10:00 2025-01-01 00:11:00           1.0",
    "crumbs": [
      "Case study"
    ]
  },
  {
    "objectID": "pages/case_study.html#calculate-summary-statistics",
    "href": "pages/case_study.html#calculate-summary-statistics",
    "title": "Case study",
    "section": "Calculate summary statistics",
    "text": "Calculate summary statistics\nFinally, we define a small utility function that calculates the mean, standard deviation, and a 95% confidence interval for a numeric series. The function handles small‚Äësample edge cases explicitly and uses the t‚Äëdistribution, which is appropriate when the sample size is modest.\n\n\ndef summary_stats(data):\n    \"\"\"\n    Calculate mean, standard deviation and 95% confidence interval (CI).\n\n    CI is calculated using the t-distribution, which is appropriate for\n    small samples and converges to the normal distribution as the sample\n    size increases.\n\n    Parameters\n    ----------\n    data : pandas.Series\n        Data to use in the calculation.\n\n    Returns\n    -------\n    dict[str, float]\n        A dictionary with keys `mean`, `std_dev`, `ci_lower` and `ci_upper`.\n        Each value is a float, or `numpy.nan` if it can't be computed.\n    \"\"\"\n    # Drop missing values\n    data = data.dropna()\n\n    # Find number of observations\n    count = len(data)\n\n    # If there are no observations, then set all to NaN\n    if count == 0:\n        mean, std_dev, ci_lower, ci_upper = np.nan, np.nan, np.nan, np.nan\n\n    # If there are 1 or 2 observations, can do mean but not other statistics\n    elif count &lt; 3:\n        mean = data.mean()\n        std_dev, ci_lower, ci_upper = np.nan, np.nan, np.nan\n\n    # With more than two observations, can calculate all...\n    else:\n        mean = data.mean()\n        std_dev = data.std()\n\n        # If there is no variation, then CI is equal to the mean\n        if np.var(data) == 0:\n            ci_lower, ci_upper = mean, mean\n        else:\n            # 95% CI based on the t-distribution\n            ci_lower, ci_upper = st.t.interval(\n                confidence=0.95,\n                df=count-1,\n                loc=mean,\n                scale=st.sem(data)\n            )\n\n    return {\n        \"mean\": mean,\n        \"std_dev\": std_dev,\n        \"ci_lower\": ci_lower,\n        \"ci_upper\": ci_upper\n    }\n\n\n\n\n\nWe apply summary_stats() to the waiting times.\n\n\nresults = summary_stats(processed_data[\"wait_minutes\"])\n\n# Format dictionary for display\nformatted_results = json.dumps(results, indent=4)\nprint(formatted_results)\n\n{\n    \"mean\": 4.166666666666667,\n    \"std_dev\": 2.786873995477131,\n    \"ci_lower\": 1.2420217719136457,\n    \"ci_upper\": 7.091311561419689\n}",
    "crumbs": [
      "Case study"
    ]
  },
  {
    "objectID": "pages/back_tests.html",
    "href": "pages/back_tests.html",
    "title": "Back tests",
    "section": "",
    "text": "Choose your language:¬†¬†\n    Python\n    R",
    "crumbs": [
      "Types of test",
      "Back tests"
    ]
  },
  {
    "objectID": "pages/test_coverage.html",
    "href": "pages/test_coverage.html",
    "title": "Test coverage",
    "section": "",
    "text": "Choose your language:¬†¬†\n    Python\n    R",
    "crumbs": [
      "Test coverage"
    ]
  },
  {
    "objectID": "pages/functional_tests.html",
    "href": "pages/functional_tests.html",
    "title": "Functional tests",
    "section": "",
    "text": "Choose your language:¬†¬†\n    Python\n    R",
    "crumbs": [
      "Types of test",
      "Functional tests"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Testing in Research Workflows",
    "section": "",
    "text": "Testing is an essential part of reproducible and reliable research. This practical course explains how to write and run tests, covering key ideas such as unit and integration testing, test coverage, and automated testing with GitHub Actions. Using hands-on examples in Python and R, you‚Äôll learn how to build tests and include them in your research workflow."
  },
  {
    "objectID": "index.html#about-this-course",
    "href": "index.html#about-this-course",
    "title": "Testing in Research Workflows",
    "section": "",
    "text": "Testing is an essential part of reproducible and reliable research. This practical course explains how to write and run tests, covering key ideas such as unit and integration testing, test coverage, and automated testing with GitHub Actions. Using hands-on examples in Python and R, you‚Äôll learn how to build tests and include them in your research workflow."
  },
  {
    "objectID": "index.html#instructors",
    "href": "index.html#instructors",
    "title": "Testing in Research Workflows",
    "section": "Instructors",
    "text": "Instructors\n\n\n\n\n\n\n\n\n\nAmy Heather\nPostdoctoral Research Associate at the University of Exeter\n  ORCID    GitHub    LinkedIn \n\n\n\n\n\n\n\n\n\n\nTom Monks\nAssociate Professor of Health Data Science at the University of Exeter\n  ORCID    GitHub    LinkedIn"
  },
  {
    "objectID": "index.html#funding",
    "href": "index.html#funding",
    "title": "Testing in Research Workflows",
    "section": "Funding",
    "text": "Funding\nThis course was developed as part of the STARS project. STARS is supported by the Medical Research Council [grant number MR/Z503915/1]."
  },
  {
    "objectID": "pages/write_basic_test.html",
    "href": "pages/write_basic_test.html",
    "title": "How to write a basic test",
    "section": "",
    "text": "Choose your language:¬†¬†\n    Python\n    R",
    "crumbs": [
      "Introduction to writing and running tests",
      "How to write a basic test"
    ]
  },
  {
    "objectID": "pages/write_basic_test.html#what-is-pytest",
    "href": "pages/write_basic_test.html#what-is-pytest",
    "title": "How to write a basic test",
    "section": "What is pytest?",
    "text": "What is pytest?\nPytest is a popular framework for testing in Python, widely used in software development and data science.\nYou should install the pytest package into your environment from either conda or PyPI:\nconda install pytest\n# or\npip install pytest",
    "crumbs": [
      "Introduction to writing and running tests",
      "How to write a basic test"
    ]
  },
  {
    "objectID": "pages/write_basic_test.html#what-a-pytest-test-looks-like",
    "href": "pages/write_basic_test.html#what-a-pytest-test-looks-like",
    "title": "How to write a basic test",
    "section": "What a pytest test looks like",
    "text": "What a pytest test looks like\nIn pytest, any function whose name starts with test_ is treated as a test. Inside the function you write one or more assert statements. If an assertion fails, pytest will return an error message explaining what went wrong.\n\nimport pytest\n\n\ndef test_example():\n    \"\"\"Simple test confirming 2 + 2 = 4\"\"\"\n    result = 2 + 2\n    assert result == 4",
    "crumbs": [
      "Introduction to writing and running tests",
      "How to write a basic test"
    ]
  },
  {
    "objectID": "pages/write_basic_test.html#testthat",
    "href": "pages/write_basic_test.html#testthat",
    "title": "How to write a basic test",
    "section": "testthat",
    "text": "testthat\ntestthat is a popular framework for testing in R, widely used in software development and data science.\nYou should install the testthat package into your environment from CRAN.\ninstall.packages(\"testthat\")",
    "crumbs": [
      "Introduction to writing and running tests",
      "How to write a basic test"
    ]
  },
  {
    "objectID": "pages/write_basic_test.html#what-a-testthat-test-looks-like",
    "href": "pages/write_basic_test.html#what-a-testthat-test-looks-like",
    "title": "How to write a basic test",
    "section": "What a testthat test looks like",
    "text": "What a testthat test looks like\nTests are created using test_that(). They are built around expectations like expect_true(), expect_false(), expect_equal(), expect_error(), and others (see package index for more).",
    "crumbs": [
      "Introduction to writing and running tests",
      "How to write a basic test"
    ]
  },
  {
    "objectID": "pages/write_basic_test.html#simple-test-example",
    "href": "pages/write_basic_test.html#simple-test-example",
    "title": "How to write a basic test",
    "section": "Simple test example",
    "text": "Simple test example\n\nlibrary(testthat)\n\n\ntest_that(\"2 add 2 equals 4\", {\n  result &lt;- 2L + 2L\n  expect_equal(result, 4L)\n})\n\nTest passed with 1 success üòÄ.",
    "crumbs": [
      "Introduction to writing and running tests",
      "How to write a basic test"
    ]
  },
  {
    "objectID": "pages/write_basic_test.html#a-simple-test-for-summary_stats",
    "href": "pages/write_basic_test.html#a-simple-test-for-summary_stats",
    "title": "How to write a basic test",
    "section": "A simple test for summary_stats",
    "text": "A simple test for summary_stats\nHere is a minimal example using the summary_stats function from the case study. For a single value, the function should return that value as the mean and NaN for the other statistics, because there is not enough data to define a standard deviation or confidence interval.\n\n\nimport pandas as pd\nimport pytest\n\n\ndef test_summary_stats_single_value():\n    \"\"\"Running summary_stats on a single value should only return mean.\"\"\"\n    data = pd.Series([10])\n    res = summary_stats(data)\n    assert res[\"mean\"] == 10\n    assert pd.isna(res[\"std_dev\"])\n    assert pd.isna(res[\"ci_lower\"])\n    assert pd.isna(res[\"ci_upper\"])\n\n\n\nTODO.",
    "crumbs": [
      "Introduction to writing and running tests",
      "How to write a basic test"
    ]
  },
  {
    "objectID": "pages/why_test.html",
    "href": "pages/why_test.html",
    "title": "When and why to run tests?",
    "section": "",
    "text": "Testing is not unique to software development. It is an essential part of research. Most researchers already test their work informally: they interrogate raw data for issues, scan tables, inspect plots, and check that values fall within plausible ranges.\nFormal testing simply records those expectations in code so they can be run consistently over time, catching issues as they arise rather than months later. Tests ask questions like:\nThis is the same logic you apply when checking results manually, just automated so you can repeat it systematically.",
    "crumbs": [
      "When and why to run tests?"
    ]
  },
  {
    "objectID": "pages/why_test.html#why-tests-matter-in-research-projects",
    "href": "pages/why_test.html#why-tests-matter-in-research-projects",
    "title": "When and why to run tests?",
    "section": "Why tests matter in research projects",
    "text": "Why tests matter in research projects\nWriting tests pays off because research code and data evolve. When you change your code, introduce new features, or update your data, you risk breaking things that used to work. Tests catch these problems early.\nThey help you verify that:\n\nYour logic and processes are working as you believe they are.\nRecent changes don‚Äôt break existing code.\nUpdated datasets are still valid and free from unexpected anomalies.\nYour results remain consistent and reproducible.\n\nOver time, when multiple people work on a project, or when you revisit analyses months later, tests become invaluable. They ensure that re-running your work produces the same results as it did previously, and that anyone depending on your outputs can trust them.\nUltimately, tests are not about best practice. They are about verifying your analysis, so you can trust that your results mean what you think they mean.",
    "crumbs": [
      "When and why to run tests?"
    ]
  },
  {
    "objectID": "pages/why_test.html#when-to-write-tests",
    "href": "pages/why_test.html#when-to-write-tests",
    "title": "When and why to run tests?",
    "section": "When to write tests",
    "text": "When to write tests\nYou don‚Äôt need a finished analysis to start testing. Even a single function or data processing step is worth testing. As you build your analysis, follow a simple pattern:\n\nWrite a piece of code (a function, data processing step, calculation).\nInspect the output to check it looks right.\nTurn that check into a test so you can run it automatically.\nIf you spot a bug, write a test that catches it.\nFix the bug, knowing your test will catch it if it happens again.\n\nThis way, testing becomes part of your natural workflow rather than a separate task.\nAvoiding leaving all testing until the end of your analysis. Problems discovered late are much harder to fix, and you may not fully understand their impact on your results. Testing as you go makes the process feel natural and keeps issues manageable.\n\n\n\n\n\n\nNoteTest-driven development\n\n\n\nSome software engineers write tests before code - this is called ‚Äútest-driven development‚Äù. This can feel less relevant in exploratory academic research, but if it suits your workflow, it is worth trying.",
    "crumbs": [
      "When and why to run tests?"
    ]
  },
  {
    "objectID": "pages/why_test.html#when-to-run-tests",
    "href": "pages/why_test.html#when-to-run-tests",
    "title": "When and why to run tests?",
    "section": "When to run tests",
    "text": "When to run tests\nRun tests regularly after any code or data changes, as catching errors earlier makes them easier to fix.\nThis practice of re-running tests is called regression testing, and it ensures recent changes haven‚Äôt introduced errors.",
    "crumbs": [
      "When and why to run tests?"
    ]
  },
  {
    "objectID": "pages/run_tests.html",
    "href": "pages/run_tests.html",
    "title": "How to run tests",
    "section": "",
    "text": "Choose your language:¬†¬†\n    Python\n    R",
    "crumbs": [
      "Introduction to writing and running tests",
      "How to run tests"
    ]
  },
  {
    "objectID": "pages/run_tests.html#required-structure-for-running-tests-from-the-command-line",
    "href": "pages/run_tests.html#required-structure-for-running-tests-from-the-command-line",
    "title": "How to run tests",
    "section": "Required structure for running tests from the command line",
    "text": "Required structure for running tests from the command line\nThis approach works when you have:\n\n1. Test files that import your analysis code\nYour test files need to import the functions, classes, or modules you want to test. This can be done in several ways depending on your project structure:\n# If your code is packaged\nfrom waitingtimes.patient_analysis import summary_stats\n\n# If your code is in a local file in the same directory\nfrom patient_analysis import summary_stats\n\n# If your code is in a subdirectory\nfrom src.analysis import summary_stats\n\n\n2. Test files that following the test_ naming convention\nPytest automatically discovers and runs tests when your test files start with test_. It is also typical (but not mandatory) to store test files in a folder called tests/. For example:\ntests/\n‚îú‚îÄ‚îÄ test_back.py\n‚îú‚îÄ‚îÄ test_functional.py\n‚îî‚îÄ‚îÄ test_unit.py",
    "crumbs": [
      "Introduction to writing and running tests",
      "How to run tests"
    ]
  },
  {
    "objectID": "pages/run_tests.html#common-pytest-commands",
    "href": "pages/run_tests.html#common-pytest-commands",
    "title": "How to run tests",
    "section": "Common pytest commands",
    "text": "Common pytest commands\nOnce your project follows these conventions, you can run tests from a terminal, PowerShell, or command prompt (depending on your OS). Common commands include:\n# Run all tests in the current directory and subdirectories\npytest\n\n# Run all tests in the tests/ directory\npytest tests/\n\n# Run tests from a specific file\npytest tests/test_filename.py\n\n# Run a specific test function\npytest tests/test_filename.py::test_function_name",
    "crumbs": [
      "Introduction to writing and running tests",
      "How to run tests"
    ]
  },
  {
    "objectID": "pages/run_tests.html#example-package-structure",
    "href": "pages/run_tests.html#example-package-structure",
    "title": "How to run tests",
    "section": "Example: package structure",
    "text": "Example: package structure\nWhen your code is structured as a package, your project might look like:\nproject/\n‚îú‚îÄ‚îÄ data/\n‚îÇ   ‚îî‚îÄ‚îÄ patient_data.csv\n‚îú‚îÄ‚îÄ pyproject.toml\n‚îú‚îÄ‚îÄ README.md\n‚îú‚îÄ‚îÄ src/\n‚îÇ   ‚îî‚îÄ‚îÄ waitingtimes/\n‚îÇ       ‚îú‚îÄ‚îÄ __init__.py\n‚îÇ       ‚îî‚îÄ‚îÄ patient_analysis.py\n‚îî‚îÄ‚îÄ tests/\n    ‚îú‚îÄ‚îÄ test_intro_simple.py\n    ‚îî‚îÄ‚îÄ ...\nThe video below demonstrates running tests on a package structured this way. In the video we:\n\nUse tree to display the file structure (matches that shown above).\nActivate our environment: conda activate hdruk_tests (which includes pytest).\nInstall our local package (if not already installed): pip install -e ..\nVerify the installation with conda list, confirming our waitingtimes package appears.\nShow you the test file (nano tests/test_intro_simple.py) (matches the one from the previous page on writing basic tests).\nRun the test with pytest tests/test_intro_simple.py - and it passes! üéâ\n\n\nIf you‚Äôre unfamiliar with how to set up a package, check out our tutorial on packaging your research project.",
    "crumbs": [
      "Introduction to writing and running tests",
      "How to run tests"
    ]
  },
  {
    "objectID": "pages/run_tests.html#example-non-package-structure",
    "href": "pages/run_tests.html#example-non-package-structure",
    "title": "How to run tests",
    "section": "Example: Non-package structure",
    "text": "Example: Non-package structure\nYou don‚Äôt need a full package to use pytest. When you code exists in .py files but isn‚Äôt packaged, you can still run tests from the terminal. Your project might, for example, look like:\nproject/\n‚îú‚îÄ‚îÄ patient_analysis.py\n‚îî‚îÄ‚îÄ test_intro_simple.py\nIn the video below, we:\n\nUse tree to display the file structure - there is just a .py file with the summary_stats() function and test_intro_simple.py file alongside it.\nView the test file with nano test_intro_simple.py, showing it imports locally since files are in the same folder.\nRun the test with pytest, since the file follows the test_ naming pattern.",
    "crumbs": [
      "Introduction to writing and running tests",
      "How to run tests"
    ]
  },
  {
    "objectID": "pages/run_tests.html#alternative-options",
    "href": "pages/run_tests.html#alternative-options",
    "title": "How to run tests",
    "section": "Alternative options",
    "text": "Alternative options\nWhile running tests from the command line is the recommended approach, there are alternative tools for specific use cases.\n\ntestbook\ntestbook allows you to test code within Jupyter notebooks:\n# Install: pip install testbook\nfrom testbook import testbook\n\n@testbook('my_notebook.ipynb', execute=True)\ndef test_notebook_function(tb):\n    func = tb.ref(\"add\")\n    assert func(2, 3) == 5\n\n\nipytest\nipytest lets you run pytest directly inside Jupyter notebook cells:\n# Install: pip install ipytest\nimport ipytest\nipytest.autoconfig()\n\n# In another cell\ndef add(a, b):\n    return a + b\n\n# In a test cell\n%%ipytest\ndef test_add():\n    assert add(2, 3) == 5\n\n\nWhy command line testing is better\nRunning tests from the terminal with code organised in .py files and a modular structure is the preferred approach because:\n\nTest code is separate from analysis code, making both easier to understand and maintain.\nTests can be run automatically in continuous integration (CI) pipelines, before commits, or on schedule.\nAs your project grows, you can easily add more test files and organise them logically without cluttering notebooks or scripts.",
    "crumbs": [
      "Introduction to writing and running tests",
      "How to run tests"
    ]
  },
  {
    "objectID": "pages/github_actions.html",
    "href": "pages/github_actions.html",
    "title": "Running tests via GitHub actions",
    "section": "",
    "text": "Choose your language:¬†¬†\n    Python\n    R",
    "crumbs": [
      "Running tests via GitHub actions"
    ]
  }
]